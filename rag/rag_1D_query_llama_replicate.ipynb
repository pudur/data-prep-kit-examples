{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Data using LLM\n",
    "\n",
    "Here is the overall RAG pipeline.   In this notebook, we will do steps (5), (6), (7), (8), (9)\n",
    "- Importing data is already done in this notebook [rag_1_B_load_data.ipynb](rag_1_B_load_data.ipynb)\n",
    "- üëâ Step 5: Calculate embedding for user query\n",
    "- üëâ Step 6 & 7: Send the query to vector db to retrieve relevant documents\n",
    "- üëâ Step 8 & 9: Send the query and relevant documents (returned above step) to LLM and get answers to our query\n",
    "\n",
    "![image missing](../media/rag-overview-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_config import MY_CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Create a .env file with the following properties.  You can use [env.txt](../env.txt) as starting point\n",
    "\n",
    "---\n",
    "\n",
    "```text\n",
    "REPLICATE_API_TOKEN=YOUR_TOKEN_GOES_HERE\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Configurations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ config REPLICATE_API_TOKEN found\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "## Load Settings from .env file\n",
    "from dotenv import find_dotenv, dotenv_values\n",
    "\n",
    "# _ = load_dotenv(find_dotenv()) # read local .env file\n",
    "config = dotenv_values(find_dotenv())\n",
    "\n",
    "# debug\n",
    "# print (config)\n",
    "\n",
    "MY_CONFIG.REPLICATE_API_TOKEN = config.get('REPLICATE_API_TOKEN')\n",
    "\n",
    "if  MY_CONFIG.REPLICATE_API_TOKEN:\n",
    "    print (\"‚úÖ config REPLICATE_API_TOKEN found\")\n",
    "else:\n",
    "    raise Exception (\"'‚ùå REPLICATE_API_TOKEN' is not set.  Please set it above to continue...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Vector Database\n",
    "\n",
    "Milvus can be embedded and easy to use.\n",
    "\n",
    "<span style=\"color:blue;\">Note: If you encounter an error about unable to load database, try this: </span>\n",
    "\n",
    "- <span style=\"color:blue;\">In **vscode** : **restart the kernel** of previous notebook. This will release the db.lock </span>\n",
    "- <span style=\"color:blue;\">In **Jupyter**: Do `File --> Close and Shutdown Notebook` of previous notebook. This will release the db.lock</span>\n",
    "- <span style=\"color:blue;\">Re-run this cell again</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to Milvus instance: ./rag_1_dpk.db\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "milvus_client = MilvusClient(MY_CONFIG.DB_URI)\n",
    "\n",
    "print (\"‚úÖ Connected to Milvus instance:\", MY_CONFIG.DB_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-: Setup Embeddings\n",
    "\n",
    "Use the same embeddings we used to index our documents!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sujee/apps/anaconda3/envs/data-prep-kit-rag-workshop-dev3/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/home/sujee/apps/anaconda3/envs/data-prep-kit-rag-workshop-dev3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(MY_CONFIG.EMBEDDING_MODEL)\n",
    "\n",
    "def get_embeddings (str):\n",
    "    embeddings = model.encode(str, normalize_embeddings=True)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings len = 384\n",
      "embeddings[:5] =  [ 0.02468893  0.10352131  0.02752644 -0.08551719 -0.01412828]\n"
     ]
    }
   ],
   "source": [
    "# Test embeddings\n",
    "embeddings = get_embeddings('Paris 2024 Olympics')\n",
    "print ('embeddings len =', len(embeddings))\n",
    "print ('embeddings[:5] = ', embeddings[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Search and RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get relevant documents using vector / sementic search\n",
    "\n",
    "def fetch_relevant_documents (query : str) :\n",
    "    search_res = milvus_client.search(\n",
    "        collection_name=MY_CONFIG.COLLECTION_NAME,\n",
    "        data = [get_embeddings(query)], # Use the `emb_text` function to convert the question to an embedding vector\n",
    "        limit=3,  # Return top 3 results\n",
    "        search_params={\"metric_type\": \"IP\", \"params\": {}},  # Inner product distance\n",
    "        output_fields=[\"text\"],  # Return the text field\n",
    "    )\n",
    "    # print (search_res)\n",
    "\n",
    "    retrieved_docs_with_distances = [\n",
    "        {'text': res[\"entity\"][\"text\"], 'distance' : res[\"distance\"]} for res in search_res[0]\n",
    "    ]\n",
    "    return retrieved_docs_with_distances\n",
    "## --- end ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize LLM\n",
    "\n",
    "### LLM Choices at Replicate\n",
    "\n",
    "- llama 3.1 : Latest\n",
    "    - **meta/meta-llama-3.1-405b-instruct** : Meta's flagship 405 billion parameter language model, fine-tuned for chat completions\n",
    "- Base version of llama-3 from meta\n",
    "    - [meta/meta-llama-3-8b](https://replicate.com/meta/meta-llama-3-8b) : Base version of Llama 3, an 8 billion parameter language model from Meta.\n",
    "    - **meta/meta-llama-3-70b** : 70 billion\n",
    "- Instruct versions of llama-3 from meta, fine tuned for chat completions\n",
    "    - **meta/meta-llama-3-8b-instruct** : An 8 billion parameter language model from Meta, \n",
    "    - **meta/meta-llama-3-70b-instruct** : 70 billion\n",
    "\n",
    "References \n",
    "\n",
    "- https://docs.llamaindex.ai/en/stable/examples/llm/llama_2/?h=replicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = MY_CONFIG.REPLICATE_API_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import replicate\n",
    "\n",
    "def ask_LLM (question, relevant_docs):\n",
    "    context = \"\\n\".join(\n",
    "        [doc['text'] for doc in relevant_docs]\n",
    "    )\n",
    "    print ('============ context (this is the context supplied to LLM) ============')\n",
    "    print (context)\n",
    "    print ('============ end  context ============', flush=True)\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "    Human: You are an AI assistant. You are able to find answers to the questions from the contextual passage snippets provided.\n",
    "    \"\"\"\n",
    "    user_prompt = f\"\"\"\n",
    "    Use the following pieces of information enclosed in <context> tags to provide an answer to the question enclosed in <question> tags.\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "    <question>\n",
    "    {question}\n",
    "    </question>\n",
    "    \"\"\"\n",
    "\n",
    "    print ('============ here is the answer from LLM... STREAMING... =====')\n",
    "    # The meta/meta-llama-3-8b-instruct model can stream output as it's running.\n",
    "    for event in replicate.stream(\n",
    "        MY_CONFIG.LLM_MODEL,\n",
    "        input={\n",
    "            \"top_k\": 1,\n",
    "            \"top_p\": 0.95,\n",
    "            \"prompt\": user_prompt,\n",
    "            \"max_tokens\": 1024,\n",
    "            \"temperature\": 0.1,\n",
    "            \"system_prompt\": system_prompt,\n",
    "            \"length_penalty\": 1,\n",
    "           # \"max_new_tokens\": 512,\n",
    "            \"stop_sequences\": \"<|end_of_text|>,<|eot_id|>\",\n",
    "            \"prompt_template\": \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\n{system_prompt}<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n{prompt}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
    "            \"presence_penalty\": 0,\n",
    "            \"log_performance_metrics\": False\n",
    "        },\n",
    "    ):\n",
    "        print(str(event), end=\"\")\n",
    "    ## ---\n",
    "    print ('\\n======  end LLM answer ======\\n', flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ context (this is the context supplied to LLM) ============\n",
      "FEDERAL RESERVE press release\n",
      "Voting for the monetary policy action were Jerome H. Powell, Chair; John C. Williams, Vice Chair; Thomas I. Barkin; Michael S. Barr; Raphael W. Bostic; Michelle W. Bowman; Lisa D. Cook; Mary C. Daly; Austan D. Goolsbee; Philip N. Jefferson; Adriana D. Kugler; and Christopher J. Waller. Austan D. Goolsbee voted as an alternate member at this meeting.\n",
      "FEDERAL RESERVE press release\n",
      "Voting for the monetary policy action were Jerome H. Powell, Chair; John C. Williams, Vice Chair; Thomas I. Barkin; Michael S. Barr; Raphael W. Bostic; Lisa D. Cook; Mary C. Daly; Beth M. Hammack; Philip N. Jefferson; Adriana D. Kugler; and Christopher J. Waller. Voting against this action was Michelle W. Bowman, who preferred to lower the target range for the federal funds rate by 1/4 percentage point at this meeting.\n",
      "Attachment\n",
      "For media inquiries, please email media@frb.gov or call 202-452-2955.\n",
      "============ end  context ============\n",
      "============ here is the answer from LLM... STREAMING... =====\n",
      "According to the Federal Reserve press release, the following members voted:\n",
      "\n",
      "1. Jerome H. Powell, Chair\n",
      "2. John C. Williams, Vice Chair\n",
      "3. Thomas I. Barkin\n",
      "4. Michael S. Barr\n",
      "5. Raphael W. Bostic\n",
      "6. Lisa D. Cook\n",
      "7. Mary C. Daly\n",
      "8. Beth M. Hammack\n",
      "9. Philip N. Jefferson\n",
      "10. Adriana D. Kugler\n",
      "11. Christopher J. Waller\n",
      "\n",
      "Additionally, Austan D. Goolsbee voted as an alternate member at the meeting. Michelle W. Bowman voted against the action, preferring to lower the target range for the federal funds rate by 1/4 percentage point.\n",
      "======  end LLM answer ======\n",
      "\n",
      "CPU times: user 214 ms, sys: 152 ms, total: 366 ms\n",
      "Wall time: 19.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Papers\n",
    "# question = \"What was the training data used to train Granite model?\"\n",
    "\n",
    "## FOMC\n",
    "question = \"Which members voted?\"\n",
    "\n",
    "\n",
    "relevant_docs = fetch_relevant_documents(question)\n",
    "ask_LLM(question=question, relevant_docs=relevant_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ context (this is the context supplied to LLM) ============\n",
      "FEDERAL RESERVE press release\n",
      "In light of the progress on inflation and the balance of risks, the Committee decided to lower the target range for the federal funds rate by 1/2 percentage point to 4-3/4 to 5 percent. In considering additional adjustments to the target range for the federal funds rate, the Committee will carefully assess incoming data, the evolving outlook, and the balance of risks. The Committee will continue reducing its holdings of Treasury securities and agency debt and agency mortgage-backed securities. The Committee is strongly committed to supporting maximum employment and returning inflation to its 2 percent objective.\n",
      "FEDERAL RESERVE press release\n",
      "In support of its goals, the Committee decided to maintain the target range for the federal funds rate at 5-1/4 to 5-1/2 percent. In considering any adjustments to the target range for the federal funds rate, the Committee will carefully assess incoming data, the evolving outlook, and the balance of risks. The Committee does not expect it will be appropriate to reduce the target range until it has gained greater confidence that inflation is moving sustainably toward 2 percent. In addition, the Committee will continue reducing its holdings of Treasury securities and agency debt and agency mortgage-backed securities. The Committee is strongly committed to returning inflation to its 2 percent objective.\n",
      "Decisions Regarding Monetary Policy Implementation\n",
      "The Federal Reserve has made the following decisions to implement the monetary policy stance announced by the Federal Open Market Committee in its statement on September 18, 2024:\n",
      "¬∑ The Board of Governors of the Federal Reserve System voted unanimously to lower the interest rate paid on reserve balances to 4.9 percent, effective September 19, 2024.\n",
      "¬∑ As part of its policy decision, the Federal Open Market Committee voted to direct the Open Market Desk at the Federal Reserve Bank of New York, until instructed otherwise, to execute transactions in the System Open Market Account in accordance with the following domestic policy directive:\n",
      "\"Effective September 19, 2024, the Federal Open Market Committee directs the Desk to: o Undertake open market operations as necessary to maintain the federal funds rate in a target range of 4-3/4 to 5 percent.\n",
      "o Conduct standing overnight repurchase agreement operations with a minimum bid rate of 5 percent and with an aggregate operation limit of $500 billion.\n",
      "o Conduct standing overnight reverse repurchase agreement operations at an offering rate of 4.8 percent and with a per-counterparty limit of $160 billion per day.\n",
      "o Roll over at auction the amount of principal payments from the Federal Reserve's holdings of Treasury securities maturing in each calendar month that exceeds a cap of $25 billion per month. Redeem Treasury coupon securities up to this monthly cap and Treasury bills to the extent that coupon principal payments are less than the monthly cap.\n",
      "o Reinvest the amount of principal payments from the Federal Reserve's holdings of agency debt and agency mortgage-backed securities (MBS) received in each calendar month that exceeds a cap of $35 billion per month into Treasury securities to roughly match the maturity composition of Treasury securities outstanding.\n",
      "o Allow modest deviations from stated amounts for reinvestments, if needed for operational reasons.\n",
      "o Engage in dollar roll and coupon swap transactions as necessary to facilitate settlement of the Federal Reserve's agency MBS transactions.\"\n",
      "¬∑ In a related action, the Board of Governors of the Federal Reserve System voted unanimously to approve a 1/2 percentage point decrease in the primary credit rate to 5 percent, effective September 19, 2024. In taking this action, the Board approved requests to establish that rate submitted by the Board of Directors of the Federal Reserve Bank of Atlanta.\n",
      "============ end  context ============\n",
      "============ here is the answer from LLM... STREAMING... =====\n",
      "According to the Federal Reserve press release, the rate cut would take effect on September 19, 2024.\n",
      "======  end LLM answer ======\n",
      "\n",
      "CPU times: user 41.6 ms, sys: 57.3 ms, total: 98.9 ms\n",
      "Wall time: 3.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Papers\n",
    "# question = \"What is attention mechanism?\"\n",
    "\n",
    "## FOMC\n",
    "# question = \"What is the target inflation rate?\"\n",
    "question = \"When would the rate cut take effect?\"\n",
    "\n",
    "relevant_docs = fetch_relevant_documents(question)\n",
    "ask_LLM(question=question, relevant_docs=relevant_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ context (this is the context supplied to LLM) ============\n",
      "FEDERAL RESERVE press release\n",
      "Voting for the monetary policy action were Jerome H. Powell, Chair; John C. Williams, Vice Chair; Thomas I. Barkin; Michael S. Barr; Raphael W. Bostic; Michelle W. Bowman; Lisa D. Cook; Mary C. Daly; Austan D. Goolsbee; Philip N. Jefferson; Adriana D. Kugler; and Christopher J. Waller. Austan D. Goolsbee voted as an alternate member at this meeting.\n",
      "FEDERAL RESERVE press release\n",
      "Voting for the monetary policy action were Jerome H. Powell, Chair; John C. Williams, Vice Chair; Thomas I. Barkin; Michael S. Barr; Raphael W. Bostic; Lisa D. Cook; Mary C. Daly; Beth M. Hammack; Philip N. Jefferson; Adriana D. Kugler; and Christopher J. Waller. Voting against this action was Michelle W. Bowman, who preferred to lower the target range for the federal funds rate by 1/4 percentage point at this meeting.\n",
      "FEDERAL RESERVE press release\n",
      "could impede the attainment of the Committee's goals. The Committee's assessments will take into account a wide range of information, including readings on labor market conditions, inflation pressures and inflation expectations, and financial and international developments.\n",
      "============ end  context ============\n",
      "============ here is the answer from LLM... STREAMING... =====\n",
      "I'm happy to help! However, I don't see any information about the moon landing in the provided context. The context appears to be related to the Federal Reserve and monetary policy decisions. Therefore, I cannot provide an answer to the question about the moon landing. If you could provide more context or clarify the question, I'll do my best to assist you.\n",
      "======  end LLM answer ======\n",
      "\n",
      "CPU times: user 121 ms, sys: 64.1 ms, total: 185 ms\n",
      "Wall time: 7.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "question = \"When was the moon landing?\"\n",
    "relevant_docs = fetch_relevant_documents(question)\n",
    "ask_LLM(question=question, relevant_docs=relevant_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
